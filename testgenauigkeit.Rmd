---
title: "Wie zuverlässig sind Testergebnisse?"
runtime: shiny_prerendered
author: Markus Konrad
email: markus.konrad@htw-berlin.de
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output:
    adaptivelearnr::tutorial:
        language: de
        apiserver: http://localhost:8000/
---

```{r setup, include=FALSE}
# Hinweis: Die "Unicode Overline" Notation für ein Komplementärereignis "nicht A" kann in HTML mittels A&#773;
# dargestellt werden. Das funktioniert auch in den Baumdiagrammen.

require(RAppArmor)     # auf Server notwendig für abgesicherte Codeausführung in Übungen
library(learnr)        # für Quizze, Code-Übungen, etc.
library(gradethis)     # für Evaluierung von Code-Einsendungen
library(shiny)         # für interaktive Elemente
library(ggplot2)       # für Grafiken

# folgendes ist notwendig um aktualisierte System-seitig installierte Version von pandoc zu verwenden, anstatt die in
# Shiny-Server / RStudio integrierte Variante:
rmarkdown::find_pandoc(cache = FALSE)

knitr::opts_chunk$set(echo = FALSE)

# Quizaufgaben sind momentan noch nicht richtig internationalisiert bei learnr;
# Wir überschreiben die englischsprachigen Nachrichten:
correct_msg <- "Richtig!"
incorrect_msg <- "Leider falsch. Versuch's noch ein mal."

# Das gleiche gilt für gradethis:
options("gradethis.pass" = correct_msg)
options("gradethis.fail" = incorrect_msg)   # damit werden Codevorschläge bei falscher Antwort deaktiviert
gradethis_setup()

# Werte für das Beispiel
prevalence <- 0.2 / 100.0   # P(K)
sens <- 0.97    # P(T|K)
spec <- 0.997   # P(T&#773;|K&#773;)
pos_pred_val <- sens * prevalence / (sens * prevalence + (1-spec) * (1-prevalence))   # P(K|T)
```

## Fragestellung

Eine Person fühlt sich gerade krank und macht einen Corona-Schnelltest. Leider fällt der Test positiv aus.

![Ein positiver Schnelltest](images/covid19test.jpg){height=300px}    

Der Test ist zwar positiv, aber wie sicher kann sich die Person sein, dass sie wirklich an Corona erkrankt ist, d.h. wie sicher kann sie sich sein, dass das Testergebnis korrekt ist? Die gleiche Frage könnte man sich auch stellen, wenn der Test negativ wäre: Wie sicher ist es in diesem Fall, dass die Person wirklich *nicht* an Corona infiziert ist?

Als erstes sehen wir uns den Beipackzettel des Schnelltests in der Hoffnung an, dass wir dort Antworten auf unsere Fragen finden. 

![Der Beipackzettel eines handelsüblichen COVID-19-Schnelltests.](images/covid19test-beipack.jpg){height=350px}

Versuchen wir, die Informationen zu entschlüsseln. Offenbar wurde eine Studie durchgeführt, in der Personen Proben entnommen wurden. Diese wurden einem RT-PCR-Test und einem Schnelltest (Nasal Swab) unterzogen und für jede Person wurden die Ergebnisse der beiden Tests miteinander verglichen. 

```{r clinicalstudy1}
question_numeric("Wie viele Personen haben an der Studie teilgenommen?",
 answer(437, correct = TRUE),
  allow_retry = TRUE,
  correct = correct_msg,
  incorrect = incorrect_msg
)
```
In dieser Studie sind wir nur an der Genauigkeit des Schnelltests interessiert. Dazu nehmen wir an, dass das Ergebnis des RT-PCR-Tests exakt ist und wir damit wissen, ob eine Person an Covid-19 erkrankt ist oder nicht. Wir überprüfen dann, ob der Schnelltest den Krankheitszustand der Personen richtig erkennt oder nicht. Statt Schnelltest schreiben ab hier nur kurz *Test*.      

Zunächst einmal können wir feststellen, dass wir es mit vier Möglichkeiten zu tun haben:

- Die Person ist krank und der Test ist positiv
- Die Person ist krank und der Test ist negativ
- Die Person ist gesund und der Test ist positiv
- Die Person ist gesund und der Test ist negativ

Man kann das übersichtlich als Tabelle darstellen:

|  | Test positiv | Test negativ |
|-----:|:----:|:----:|
|  **Person krank**    |   richtig positiv   |  falsch negativ    |
|  **Person gesund**    |   falsch positiv   |  richtig negativ   |

Diese Tabellendarstellung wird *Wahrheitsmatrix* oder auch *Konfusionsmatrix* genannt. Beachte, dass wir die Matrix gegenüber der Darstellung im Beipackzettel transponiert haben. 


```{r confmat}
question("Nehmen wir an, es gäbe drei Krankheitszustände: nicht erkrankt, mild erkrankt und schwer erkrankt. Wie sähe die Konfusionsmatrix für einen fiktiven Test aus, der einen dieser Zustände als Testergebnis liefert?",
  answer("So wie oben, d.h. 2 Zeilen und 2 Spalten."),
  answer("2 Zeilen und 3 Spalten."),
  answer("3 Zeilen und 2 Spalten."),
  answer("3 Zeilen und 3 Spalten.", correct = TRUE),
  answer("Es ist nicht möglich, eine Konfusionsmatrix für Tests mit mehr als zwei möglichen Antworten zu erstellen."),
  allow_retry = TRUE,
  correct = correct_msg,
  incorrect = incorrect_msg
)
```

```{r clinicalstudy2}
question_numeric("Bei wie vielen Personen in der Studie hat der Test den Krankheitszustand richtig erkannt?",
 answer(430, correct = TRUE),
  allow_retry = TRUE,
  correct = correct_msg,
  incorrect = incorrect_msg
)
```

Die Testgenauigkeit (*Total Accuracy*) im Beipackzettel gibt uns den relativen Anteil der richtigen Testergebnisse im Vergleich zu allen an, also $430/437 = 98.4\%$. Weiterhin finden wir dort mit Sensitivität (*Sensitivity*) und Spezifität (*Specificity*) zwei weitere Gütemaße, welche im Text darunter erklärt werden:

- Von 100 nachweislich positiven Covid-Fällen erkennt der Test etwa 97 Fälle richtig als positiv (Sensitivität)
- Von 100 nachweislich negativen Fällen erkennt der Test etwa 99 Fälle richtig als negativ (Spezifität)

::: summary

#### Fragestellung

Wie hoch ist die Wahrscheinlichkeit, dass ein Mensch mit positivem Corona-Test *wirklich* erkrankt ist? Wie hoch ist die Wahrscheinlichkeit, dass ein Mensch mit negativem Corona-Test *wirklich* gesund ist?  

:::

Überlege dir, wie man die Werte von Sensitivität und Spezifität aus der Tabelle im Beipackzettel berechnen kann. Warum beantworten Testgenauigkeit, Sensitivität und Spezifität nicht unsere eigentliche Fragestellung, die wir jetzt in der Zusammenfassung rechts oben sehen?

## Analyse

Zur Formalisierung des Problems stellen wir das Vorgehen in der Studie als Baumdiagramm dar, was uns später bei der Beantwortung der eigentlich Fragestellung helfen wird. Wir wissen, wer gesund und wer krank ist und überprüfen für diese Gruppen von Personen jeweils, wie der Test ausfällt:


![Baumdiagramm mit Ereignissen](images/baum1.png){height=200px}


Damit wir später gut rechnen können, definieren wir zunächst zwei Ereignisse und deren Negation. Diese entsprechen den oben genannten Möglichkeiten:

- $K$:Person krank
- $\overline K$: Person gesund
- $T$: Test positiv
- $\overline T$: Test negativ

::: summary

#### Definition der Ereignisse

- $K$:Person krank und $\overline K$: Person gesund
- $T$: Test positiv und $\overline T$: Test negativ

:::

Diese Ereignisse können wir in ein Baumdiagramm übertragen, zusammen mit den dazugehörigen Wahrscheinlichkeiten $P$:

![Baumdiagramm mit Ereignissen und deren Wahrscheinlichkeiten](images/baum2.png){height=300px}

Wie in der Frage eingangs formuliert, möchten wir wissen, wie hoch die Wahrscheinlichkeit ist, dass eine Person tatsächlich krank ist, wenn der Test positiv ausfällt. Das lässt sich mithilfe der oben definierten Ereignisse als *bedingte Wahrscheinlichkeit* formulieren – die Wahrscheinlichkeit, dass eine Person krank ist, gegeben dass der Test positiv ist: $P(K \mid T)$. Diese Wahrscheinlichkeit wird auch *positiver Vorhersagewert* genannt, aber sie taucht im obigen Baumdiagramm nicht auf. Dort sind die Ereignisse K und T vertauscht wie in $P(T \mid K)$.

```{r P_T_K}
question("Was gibt die Wahrscheinlichkeit $P(T \\mid K)$ an?",
  answer("Die Wahrscheinlichkeit, dass ein Test positiv ist, wenn die getestete Person krank ist.", correct = TRUE),
  answer("Die Wahrscheinlichkeit, dass eine Person gesund ist, wenn sie einen positiven Test hatte."),
  answer("Die Wahrscheinlichkeit, dass eine Person krank ist, wenn sie einen positiven Test hatte."),
  answer("Die Wahrscheinlichkeit, dass ein Test positiv ist, obwohl die getestete Person gesund ist."),
  allow_retry = TRUE,
  correct = correct_msg,
  incorrect = incorrect_msg
)
```

$P(T \mid K)$ wird *Sensitivität* genannt und ist ein Gütemaß für einen Test, wie wir im Beipackzettel schon gesehen haben. Die Sensitivität gibt an, wie hoch die Wahrscheinlichkeit ist, dass der Test ein positives Ergebnis anzeigt für eine tatsächlich erkrankte Person und wird daher auch *Richtig-positiv-Rate* genannt. 

Um nun den eigentlich gesuchten *positiven Vorhersagewert*, also die bedingte Wahrscheinlichkeit $P(K \mid T)$ zu berechnen, können wir den **Satz von Bayes** benutzen:


$$
P(K \mid T) = \frac{P(T \mid K) P(K)}{P(T)}.
$$

Was wir also brauchen, um $P(K \mid T)$ zu berechnen, sind drei Wahrscheinlichkeiten: $P(K)$, $P(T \mid K)$ und $P(T)$.

::: summary

#### Definition der bedingten Wahrscheinlichkeiten

$P(K \mid T)$ – Wahrscheinlichkeit, dass ein Test positiv ist, wenn die getestete Person krank ist

#### Satz von Bayes

$$
P(K \mid T) = \frac{P(T \mid K) P(K)}{P(T)}.
$$

:::

<div class="with_sidebar">

<div class="main">
$P(K)$ gibt an, wie hoch generell die Wahrscheinlichkeit ist, zu diesem Zeitpunkt an Corona erkrankt zu sein – ganz unabhängig von einem Testergebnis. Genau können wir diese Wahrscheinlichkeit niemals wissen, aber wir können einen Schätzwert nehmen, der dem Anteil der aktuell an Corona infizierten Menschen in Deutschland entspricht. Setzen wir zunächst $P(K) = `r prevalence * 100`\%$. Das ist in etwa die Prävalenz bei der ersten Coronawelle im Frühjahr 2020 in Deutschland.

Man könnte auch auf die Idee kommen, $P(K)$ aus der Studie im Beipackzettel abzulesen. Warum ist das in den meisten Fällen nicht sinnvoll? 
</div>

<div class="side">
Die Kennzahl, die aussagt wie hoch der Prozentsatz der Menschen ist, die zu einem bestimmten Zeitpunkt an einer bestimmten Krankheit leidet, wird *Prävalenz* genannt.
</div>

</div>



::: summary

#### Definition der bedingten Wahrscheinlichkeiten

$P(T \mid K)$ – Wahrscheinlichkeit, dass ein Test ein positives Ergebnis anzeigt, unter der Bedingung dass die Person tatsächlich erkrankt ist (Sensitivität)

:::

<!-- ![Der Beipackzettel eines handelsüblichen COVID 19 Schnelltests.](images/covid19test-beipack.jpg){height=350px} -->

Die Wahrscheinlichkeit $P(T \mid K)$ ist im Beipackzettel als Sensitivität schon angegeben. 

Schließlich fehlt noch $P(T)$: die Wahrscheinlichkeit dafür, dass eine Person – egal ob krank oder gesund – bei einem Test ein positives Ergebnis erhält. Hier hilft uns das *Gesetz der totalen Wahrscheinlichkeit*, das es uns erlaubt, die Wahrscheinlichkeiten für die beiden Möglichkeiten, die zu positiven Tests führen (Person krank und Person gesund), zu addieren, da sie sich gegenseitig ausschließen:

![Baumdiagramm mit beiden Möglichkeiten, die zu positiven Tests führen](images/baum3.png){height=300px}

Somit erhalten wir

$$
P(T) = P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K),
$$

und damit

$$
P(K \mid T) = \frac{P(T \mid K) P(K)}{P(T)} = \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K)}.
$$

Das bringt uns allerdings zwei neue Probleme ein: Wir brauchen $P(T \mid \overline K)$ und $P(\overline K)$. Beides können wir zum Glück über die Wahrscheinlichkeit für komplementäre Ereignisse berechnen. Damit ist $P(\overline K)$ (die generelle Wahrscheinlichkeit *nicht* krank zu sein) leicht zu errechnen, denn $P(K)$ (die generelle Wahrscheinlichkeit krank zu sein, geschätzt mittels Prävalenz) kennen wir schon: $P(\overline K) = 100\% - P(K) = `r (1 - prevalence)*100`\%$.

Fehlt zu guter letzt noch $P(T \mid \overline K)$: Die Wahrscheinlichkeit ein positives Testergebnis zu haben, wenn man eigentlich gesund ist (ein *falsch-positives Ergebnis*). Hier hilft uns ein weiteres Gütemaß für Tests weiter: die *Spezifität*, auch *Richtig-negativ Rate* genannt. Sie gibt uns die Wahrscheinlichkeit an, dass eine Person ein negatives Testergebnis erhält, wenn sie tatsächlich gesund ist, also $P(\overline T | \overline K)$. Auch die Spezifität wird oft im Beipackzettel von Schnelltests abgedruckt, wie wir schon gesehen haben. Wie wir im Baumdiagramm erkennen, ist $P(\overline T | \overline K)$ komplementär zu $P(T | \overline K)$ und damit gilt $P(T | \overline K) = 100\% - P(\overline T | \overline K)$.

::: summary

#### Satz von Bayes {.replace}

\begin{align}
P(K \mid T) &= \frac{P(T \mid K) P(K)}{P(T)} \\
            &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K)}.
\end{align}

:::

### Berechnung

Um beispielhaft zu berechnen, wie hoch die Wahrscheinlichkeit ist, dass eine Person tatsächlich krank ist, wenn sie ein positives Testergebnis erhält, nehmen wir zunächst gängige Werte für die Sensitivität und Spezifität von guten COVID Schnelltests an:

- Sensitivität: $P(T \mid K) = `r sens * 100`\%$
- Spezifität: $P(\overline T \mid \overline K) = `r spec * 100`\%$

Für die Prävalenz hatten wir $P(K) = `r prevalence * 100`\%$ angenommen.

Damit können wir die Werte in die Formel einsetzen und erhalten:

\begin{align}
P(K \mid T) &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K)} \\[10pt]
            &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + (1 - P(\overline T \mid \overline K)) (1 - P(K))} \\[10pt]
            &= \frac{`r sens` \cdot `r prevalence`}{`r sens` \cdot `r prevalence` + (1 - `r spec`) \cdot (1 - `r prevalence`)} \\[10pt]
            &= `r round(pos_pred_val, 4)`.
\end{align}

### Interpretation

Die Wahrscheinlichkeit, dass eine Person mit positivem Schnelltest tatsächlich krank ist (positiver Vorhersagewert), beträgt also nur rund $`r round(pos_pred_val * 100)`\%$. Das ist tatsächlich keine sonderlich hohe Wahrscheinlichkeit und auf den ersten Blick verwunderlich, denn sowohl Sensitivität als auch Spezifität liegen als Gütemaße im Beipackzettel des Tests nahe 100%. Auf der folgenden Seite werden wir uns genauer anschauen, warum das so ist.

---

#### Aufgabe 1

Berechnen Sie die Wahrscheinlichkeit, dass eine Person, die einen negativen Schnelltest hat, tatsächlich gesund ist. Benutzen Sie dabei die selben Parameter (Prävalenz, Sensitivität, Spezifität) wie in der obigen Beispielberechnung. Sie können dafür die Variablen `prevalence`, `sens` und `spec` im Code verwenden.

```{r neg_pred_value, exercise=TRUE, exercise.timelimit=5}

```

```{r neg_pred_value-solution}
spec * (1-prevalence) / (spec * (1-prevalence) + (1-sens) * prevalence)
```

```{r neg_pred_value-check}
grade_this({
    # P(nicht K|nicht T) berechnen
    neg_pred_val <- spec * (1-prevalence) / (spec * (1-prevalence) + (1-sens) * prevalence)
    # Prüfen d. Ergebnisses
    if (identical(round(.result, 6), round(neg_pred_val, 6))) {
        pass()
    }
    fail()  # falls nicht korrekt
})
```


<div id="neg_pred_value-hint">
Versuchen Sie, den Satz von Bayes für die bedingte Wahrscheinlichkeit $P(\overline K \mid \overline T)$ anzuwenden.
</div>


## Der Einfluss von Prävalenz und Testgenauigkeit

Schauen wir uns noch mal die Berechnung der bedingten Wahrscheinlichkeit $P(K \mid T)$ an:

\begin{align}
P(K \mid T) &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K)} \\[10pt]
            &= \frac{`r sens` \cdot `r prevalence`}{`r sens` \cdot `r prevalence` + `r 1-spec` \cdot `r 1-prevalence`} \\[10pt]
            &= `r round(pos_pred_val, 4)`.
\end{align}

Man sieht daran sehr gut, welch großen Einfluss die Prävalenz auf das Gesamtergebnis hat: Selbst bei hoher Sensitivität des Tests wird der Zähler $P(T \mid K) P(K)$ und damit das Gesamtergebnis sehr klein, wenn die Prävalenz sehr klein ist. Das macht auch intuitiv Sinn: Wenn es insgesamt sehr wenige Fälle einer Krankheit gibt, ist die Wahrscheinlichkeit vergleichsweise gering, dass eine Person ausgerechnet damit erkrankt ist, selbst wenn der Test positiv ausfällt. Dagegen ist die Wahrscheinlichkeit sehr hoch, dass eine Person an einer Krankheit erkrankt ist, bei der es gerade viele Krankheitsfälle gibt (die Prävalenz also sehr hoch ist) ganz unabhängig davon, wie gut der Test funktioniert.

Wir können das auch visualisieren, indem wir $P(K \mid T)$ in Abhängigkeit der Prävalenz darstellen für fest gewählte Sensitivität und Spezifität:

```{r}
calc_ppv <- function(prev, sens, spec) {
    sens * prev / (sens * prev + (1-spec) * (1-prev))
}

# Erstellung eines Dataframes mit der Kombination aller Parameter (kartesisches Produkt)
ppv_by_param <- expand.grid(prev = seq(0, 1, length.out = 1001),
                            sens = c(0.9, 0.97, 0.9999),
                            spec = seq(0.990, 0.999, length.out = 10))
# P(K|T) für jede Parameterkombination berechnen
ppv_by_param$ppv <- calc_ppv(ppv_by_param$prev, ppv_by_param$sens, ppv_by_param$spec)

# Darstellung P(K|T) für bestimmte Sensitivität und Spezifität in Abh. von Prävalenz
fixed_sens <- sens
fixed_spec <- spec

ppv_fixed_sens_spec <- ppv_by_param[ppv_by_param$sens == fixed_sens & ppv_by_param$spec == fixed_spec, ]

ggplot(ppv_fixed_sens_spec, aes(prev, ppv)) +
    geom_line() +
    # X-Achse in Prozent
    scale_x_continuous('Prävalenz', labels = scales::percent) +
    # Y-Achse in Prozent
    scale_y_continuous(expression("P" * (K ~ "|" ~ T )), labels = scales::percent) +
    labs(title = expression("Positiver Vorhersagewert P" * (K ~ "|" ~ T ) ~ "in Abhängigkeit der Prävalenz"),
         subtitle = sprintf("Bei Sensitivität von %.1f%% und Spezifität von %.1f%%.", fixed_sens * 100, fixed_spec * 100)) +
    theme_minimal()
```

Wir sehen, wie stark die Kurve ansteigt und schon bei einer Prävalenz von 10% können wir einem Testergebnis mit der gegebenen Sensitivität und Spezifität trauen. Für geringere Prävalenzen ist das weniger gerechtfertigt, wie hier noch mal im Detail dargestellt:


```{r, warning=FALSE}
# wie oben, nur mit Begrenzung der X-Achse
ggplot(ppv_fixed_sens_spec, aes(prev, ppv)) +
    geom_line() +
    scale_x_continuous('Prävalenz', labels = scales::percent, limits = c(0.001, 0.02)) +
    scale_y_continuous(expression("P" * (K ~ "|" ~ T )), labels = scales::percent) +
    labs(title = expression("Positiver Vorhersagewert P" * (K ~ "|" ~ T ) ~ "in Abhängigkeit der Prävalenz"),
         subtitle = sprintf("Bei Sensitivität von %.1f%% und Spezifität von %.1f%%.", fixed_sens * 100, fixed_spec * 100)) +
    theme_minimal()
```


Andererseits zeigt es auch, wie wichtig genaue Tests sind. Bei niedriger Prävalenz spielt hierbei besonders die Spezifität eine wichtige Rolle, wie folgende Grafiken zeigen:


```{r, warning=FALSE}
# Wie oben, aber mit verschiedenen Werten für die Spezifität als unterschiedlich gefärbte Linien und
# mit versch. Werten für die Sensitivität als extra Grafik (facets)
ppv_by_param$spec_lbl <- sprintf("%.1f%%", ppv_by_param$spec * 100)
ggplot(ppv_by_param, aes(prev, ppv, color = spec_lbl, group = spec_lbl)) +
    geom_line() +
    scale_x_continuous('Prävalenz', labels = scales::percent, limits = c(0.001, 0.02)) +
    scale_y_continuous(expression("P" * (K ~ "|" ~ T )), labels = scales::percent) +
    # Spezifität als diskrete Werte auffassen anstatt kontinuierliche Werte
    scale_color_discrete("Spezifität") +
    labs(title = expression("Positiver Vorhersagewert P" * (K ~ "|" ~ T )),
         subtitle = "In Abhängigkeit der Prävalenz, Sensitivität und Spezifität.") +
    # für jeden Wert der Sensitivität eine extra Grafik
    facet_wrap(vars(sens), labeller = as_labeller(function(s) {sprintf("Sensitivität %.2f%%", as.numeric(s)*100)})) +
    theme_minimal()
```

Mittels dieser interaktiven Grafik können Sie für selbst gewählte Sensitivitäts- und Spezifitätswerte den positiven Vorhersagewert in Abhängigkeit zur Prävalenz darstellen:

```{r}
# Eingaberegler für Sensitivität, Spez., und maximal dargestellte Prävalenz

fluidRow(
    column(8, plotOutput("ppv_interactive")),   # Plot Ausgabe
    column(4,
           sliderInput("slider_sens", "Sensitivität in Prozent",
                       min = 0, max = 100, value = 95, step = 0.1),
           sliderInput("slider_spec", "Spezifität in Prozent",
                       min = 0, max = 100, value = 95, step = 0.1),
           sliderInput("slider_prev_max", "Maximal dargestellte Prävalenz in Prozent (x-Achse)",
                       min = 0, max = 100, value = 2, step = 0.1)
    )
)
```

```{r, context="server"}
# Erzeugung der Plotausgabe im Shiny "Serverkontext"
output$ppv_interactive <- renderPlot({
  sens <- input$slider_sens / 100
  spec <- input$slider_spec / 100
  # Daten generieren für Prävalenz
  df <- data.frame(prev = seq(0, input$slider_prev_max / 100, length.out = 1000))
  # P(K|T) berechnen
  df$ppv <- sens * df$prev / (sens * df$prev + (1-spec) * (1-df$prev))
  
  # Plot erstellen
  ggplot(df, aes(prev, ppv)) +
    geom_line() +
    scale_x_continuous('Prävalenz', labels = scales::percent) +
    scale_y_continuous(expression("P" * (K ~ "|" ~ T )), labels = scales::percent, limits = c(0, 1)) +
    labs(title = expression("Positiver Vorhersagewert P" * (K ~ "|" ~ T ) ~ "in Abhängigkeit der Prävalenz"),
         subtitle = sprintf("Bei Sensitivität von %.1f%% und Spezifität von %.1f%%.", input$slider_sens, input$slider_spec)) +
    theme_minimal()
})
```


```{r ppv_sens}
question("Warum spielt die Sensitivität bei niedriger Prävalenz keine so starke Rolle für den positiven Vorhersagewert?",
  answer("Da bei niedriger Prävalenz unabhängig vom Testergebnis die Wahrscheinlichkeit sehr gering ist, erkrankt zu sein.", correct = TRUE),
  answer("Da bei niedriger Prävalenz die Sensitivität automatisch geringer ist."),
  answer("Da bei niedriger Prävalenz der Term $P(T \\mid K) P(K)$ immer sehr klein ausfällt, die Sensitivität $P(T \\mid K)$ also kaum einen Einfluss auf das Gesamtergebnis haben kann.", correct = TRUE),
  allow_retry = TRUE,
  correct = correct_msg,
  incorrect = incorrect_msg
)
```

Die Spezifität $P(\overline T \mid \overline K)$ hat einen großen Einfluss, denn wie wir schon gezeigt haben gilt

\begin{align}
P(K \mid T) &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + P(T \mid \overline K) P(\overline K)} \\[10pt]
            &= \frac{P(T \mid K) P(K)}{P(T \mid K) P(K) + (1 - P(\overline T \mid \overline K)) P(\overline K)},
\end{align}

und da $P(K)$ sehr klein ist, ist $P(\overline K)$ sehr groß und somit hat die Spezifität $P(\overline T \mid \overline K)$ über den Term $(1 - P(\overline T \mid \overline K)) P(\overline K)$ die "Macht" über den Nenner. Damit bewirkt eine hohe Spezifität einen kleinen Nenner und damit einen hohen positiven Vorhersagewert.

Wir sehen also: gute Tests (insbesondere mit hoher Spezifität) können hier gerade am Anfang einer Krankheitswelle einen großen Unterschied machen, denn sie erlauben es schon frühzeitig recht zuverlässig Infektionen zu erkennen, selbst wenn die Prävalenz noch niedrig ist.

Auch andere Parameter und Umstände abseits der Prävalenz und der Testgüte haben noch bedeutenden Einfluss auf das Ergebnis. Insbesondere ist es wichtig, wie gründlich der Abstrich vorgenommen wurde. Es ist auch bekannt, dass die Temperatur die Genauigkeit von COVID-Schnelltests beeinflusst. Sie sehen also, dass die Berechnungen noch deutlich komplexer werden können!

---

#### Aufgabe 2a

Analog zu den Grafiken für den positiven Vorhersagewert $P(K \mid T)$ möchten wir eine Grafik für den negativen Vorhersagewert $P(\overline K \mid \overline T)$ erstellen. Diese Grafik soll den negativen Vorhersagewert in Abhängigkeit von der Prävalenz und der Sensitivität darstellen.

Zunächst brauchen wir dazu einen *Dataframe* mit einer Reihe von Prävalenz- und Sensitivitätswerten. Erzeugen Sie einen solchen Dataframe für alle Kombinationen aus den Prävalenzwerten $0.1, 0.2, \dots, 0.9$ und den Sensitivitätswerten $0.9, 0.97$ und $0.99$. Sie können dafür die Funktion `expand.grid` verwenden. Der Dataframe sollte `nvw_param` heißen und die Spalten `praev` und `sens` haben.

```{r nvw_a, exercise=TRUE, exercise.timelimit=5, exercise.blanks = "___+"}
nvw_param <- expand.grid(praev = ___,
                         sens = ___)
nvw_param
```

```{r nvw_a-solution}
nvw_param <- expand.grid(praev = seq(0.1, 0.9, length.out = 9),
                         sens = c(0.9, 0.97, 0.99))
nvw_param
```

```{r nvw_a-check}
grade_this({
    nvw_param <- expand.grid(praev = seq(0.1, 0.9, length.out = 9),
                             sens = c(0.9, 0.97, 0.99))
    
    # Gleitkommazahlenprüfung mit näherungsweiser Übereinstimmung
    if (isTRUE(all.equal(.result, nvw_param))) {
        pass()
    }
    fail()
})
```

#### Aufgabe 2b

Berechnen Sie als nächstes den negativen Vorhersagewert $P(\overline K \mid \overline T)$ für alle gegebenen Parameter und fügen Sie das Ergebnis als Spalte `nvw` zum Dataframe `nvw_param` hinzu. Nutzen Sie dafür eine festgelegte Spezifität von $99.7\%$.

```{r nvw_b-setup}
nvw_param <- expand.grid(praev = seq(0.1, 0.9, length.out = 9),
                         sens = c(0.9, 0.97, 0.99))
nvw_param
```

```{r nvw_b, exercise=TRUE, exercise.timelimit=5, exercise.blanks = "___+", exercise.setup="nvw_b-setup"}
spez <- 0.997
nvw_param$nvw <- ___
nvw_param
```

```{r nvw_b-solution}
spez <- 0.997
nvw_param$nvw <- spez * (1-nvw_param$praev) / (spez * (1-nvw_param$praev) + (1-nvw_param$sens) * nvw_param$praev)
nvw_param
```

```{r nvw_b-check}
grade_this({
    nvw_param <- expand.grid(praev = seq(0.1, 0.9, length.out = 9),
                             sens = c(0.9, 0.97, 0.99))
    spez <- 0.997
    nvw_param$nvw <- spez * (1-nvw_param$praev) / (spez * (1-nvw_param$praev) + (1-nvw_param$sens) * nvw_param$praev)
    
    # Gleitkommazahlenprüfung mit näherungsweiser Übereinstimmung
    if (isTRUE(all.equal(.result, nvw_param))) {
        pass()
    }
    fail()
})
```

#### Aufgabe 2c

Erstellen Sie eine Grafik mit *ggplot2*, welche den negativen Vorhersagewert in Abhängigkeit der Prävalenz darstellt. Dabei sollen für die drei unterschiedlichen Werte der Sensitivität drei farblich unterschiedliche Linien dargestellt werden.

Die erzeugte Grafik sollte wie folgt aussehen:

![](images/aufg_2c_plot.png){width=400px}


```{r nvw_c-setup, exercise.setup="nvw_b-setup"}
spez <- 0.997
nvw_param$nvw <- spez * (1-nvw_param$praev) / (spez * (1-nvw_param$praev) + (1-nvw_param$sens) * nvw_param$praev)
```

```{r nvw_c, exercise=TRUE, exercise.timelimit=5, exercise.blanks = "___+", exercise.setup="nvw_c-setup"}
ggplot(nvw_param, aes(___)) +
    ___ +  # "geom_..." für Linienplot
    theme_minimal()
```

```{r nvw_c-solution}
ggplot(nvw_param, aes(praev, nvw, color = sens, group = sens)) +
    geom_line() +
    theme_minimal()
```

```{r nvw_c-code-check}
grade_this_code()
```
